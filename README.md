# 🏢 Web Scraping Fortune’s Largest U.S. Companies by Revenue

## 📌 Project Overview

This project showcases a complete web scraping pipeline to collect and analyze the **largest companies in the United States by revenue**, as published in public rankings like the Fortune 500. Built with **Python and BeautifulSoup**, the notebook extracts key company information and organizes it for data analysis, market intelligence, and visualization.

> ✅ **Objective**: Automate the collection of Fortune-ranked company data, clean and structure it, then deliver insights that matter to business stakeholders and market analysts.

---

## 🌐 What This Project Covers

- 🌎 **Data Source**: Web table listing U.S. companies ranked by revenue  
- 🛠 **Tools Used**: Python, BeautifulSoup, pandas, requests  
- 📊 **Data Fields Collected**:
  - Company Name
  - Industry
  - Revenue (in billions USD)
  - Profit
  - Employees
  - Headquarters

---

## 📈 Sample Insight: Who Leads the American Corporate Landscape?

Using this dataset, analysts and decision-makers can answer questions like:

- 🏦 Which industries dominate the Fortune list?  
- 💰 Who are the most profitable companies?  
- 🧑‍🤝‍🧑 Which companies have the largest workforce?  
- 🗺️ Where are corporate headquarters concentrated?

> This enables **competitive benchmarking, sector growth forecasting, and talent market analysis** — making it more than a scraping exercise: it’s **data-driven strategy**.

---

## 🔍 Why This Project Matters

As a data analyst or scientist, being able to **source your own data** especially from unstructured or semi-structured web content is a valuable skill. In business environments where data isn't always cleanly packaged, this shows your ability to:

- Automate external data collection  
- Parse and clean raw HTML tables  
- Transform data into decision-ready formats  
- Uncover insights with minimal input friction

> 🔧 This notebook proves that I can **build data pipelines** from scratch, even when APIs aren't available.

---

## 🛠 Tools & Technologies

- **Python**  
- **BeautifulSoup**  
- **requests**  
- **pandas**  
- **Jupyter Notebook**

---

## ✅ Skills Demonstrated

- 🧑‍💻 Web Scraping and HTML parsing  
- 🧼 Data Cleaning and Type Conversion  
- 🧠 Business Intelligence Insight Development  
- 📊 DataFrame creation and exploration with `pandas`  
- 📈 Summary Statistics and Industry Rankings

---

## 👨‍💼 About Me

I’m **Tosin Bello**, a **Data Analyst and Data Scientist** focused on using Python and machine learning to solve real-world business challenges. This project demonstrates my ability to **source, clean, and convert raw web data** into actionable insights for stakeholders.

📬 **Let’s connect**:

- **LinkedIn**: [Tosin Bello](https://www.linkedin.com/in/tosinbellofin)  
- **Email**: toshineb@email.com  

---

## 🚀 How to Use This Notebook

1. Clone the repo  
2. Install required libraries: `pip install beautifulsoup4 pandas requests`  
3. Run `Webscraping_Table.ipynb` in Jupyter  
4. Explore the final `DataFrame` and modify it for visualization, ranking, or export

---

## ⭐ If you found this useful or insightful, please give it a star and follow for more real-world data projects that matter.
