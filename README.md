# ğŸ¢ Web Scraping Fortuneâ€™s Largest U.S. Companies by Revenue

## ğŸ“Œ Project Overview

This project showcases a complete web scraping pipeline to collect and analyze the **largest companies in the United States by revenue**, as published in public rankings like the Fortune 500. Built with **Python and BeautifulSoup**, the notebook extracts key company information and organizes it for data analysis, market intelligence, and visualization.

> âœ… **Objective**: Automate the collection of Fortune-ranked company data, clean and structure it, then deliver insights that matter to business stakeholders and market analysts.

---

## ğŸŒ What This Project Covers

- ğŸŒ **Data Source**: Web table listing U.S. companies ranked by revenue  
- ğŸ›  **Tools Used**: Python, BeautifulSoup, pandas, requests  
- ğŸ“Š **Data Fields Collected**:
  - Company Name
  - Industry
  - Revenue (in billions USD)
  - Profit
  - Employees
  - Headquarters

---

## ğŸ“ˆ Sample Insight: Who Leads the American Corporate Landscape?

Using this dataset, analysts and decision-makers can answer questions like:

- ğŸ¦ Which industries dominate the Fortune list?  
- ğŸ’° Who are the most profitable companies?  
- ğŸ§‘â€ğŸ¤â€ğŸ§‘ Which companies have the largest workforce?  
- ğŸ—ºï¸ Where are corporate headquarters concentrated?

> This enables **competitive benchmarking, sector growth forecasting, and talent market analysis** â€” making it more than a scraping exercise: itâ€™s **data-driven strategy**.

---

## ğŸ” Why This Project Matters

As a data analyst or scientist, being able to **source your own data** especially from unstructured or semi-structured web content is a valuable skill. In business environments where data isn't always cleanly packaged, this shows your ability to:

- Automate external data collection  
- Parse and clean raw HTML tables  
- Transform data into decision-ready formats  
- Uncover insights with minimal input friction

> ğŸ”§ This notebook proves that I can **build data pipelines** from scratch, even when APIs aren't available.

---

## ğŸ›  Tools & Technologies

- **Python**  
- **BeautifulSoup**  
- **requests**  
- **pandas**  
- **Jupyter Notebook**

---

## âœ… Skills Demonstrated

- ğŸ§‘â€ğŸ’» Web Scraping and HTML parsing  
- ğŸ§¼ Data Cleaning and Type Conversion  
- ğŸ§  Business Intelligence Insight Development  
- ğŸ“Š DataFrame creation and exploration with `pandas`  
- ğŸ“ˆ Summary Statistics and Industry Rankings

---

## ğŸ‘¨â€ğŸ’¼ About Me

Iâ€™m **Tosin Bello**, a **Data Analyst and Data Scientist** focused on using Python and machine learning to solve real-world business challenges. This project demonstrates my ability to **source, clean, and convert raw web data** into actionable insights for stakeholders.

ğŸ“¬ **Letâ€™s connect**:

- **LinkedIn**: [Tosin Bello](https://www.linkedin.com/in/tosinbellofin)  
- **Email**: toshineb@email.com  

---

## ğŸš€ How to Use This Notebook

1. Clone the repo  
2. Install required libraries: `pip install beautifulsoup4 pandas requests`  
3. Run `Webscraping_Table.ipynb` in Jupyter  
4. Explore the final `DataFrame` and modify it for visualization, ranking, or export

---

## â­ If you found this useful or insightful, please give it a star and follow for more real-world data projects that matter.
